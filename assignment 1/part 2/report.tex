\documentclass[11pt, a4paper]{article}

% --- OPTIMIZATION SETTINGS ---
\usepackage{mathptmx} % Lightweight font (Times)
\usepackage[T1]{fontenc}
\usepackage[varqu,varl]{zi4} % Consolas-like monospaced font

% "final" forces images to show
\usepackage[final]{graphicx} 

% --- STANDARD PACKAGES ---
\usepackage{amsmath}
\usepackage{geometry}
\usepackage{booktabs}
\usepackage{fancyhdr}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{multirow}
\usepackage{adjustbox}
\usepackage{float}
\usepackage{siunitx}
\usepackage{hyperref}

% --- CONFIGURATION ---
\setlength{\emergencystretch}{2em}
\geometry{left=25mm, right=25mm, top=25mm, bottom=25mm}

\sisetup{
  parse-numbers=false,
  round-mode=figures,
  round-precision=4
}

\lstset{
  basicstyle=\ttfamily\small,
  breaklines=true,
  frame=single,
  columns=fullflexible,
  captionpos=b
}

\title{Assignment 1: Problem 2 - Gem5 MergeSort Cache Analysis}
\author{Rahate Tanishka Shivendra (22CS30043), Shivam Choudhury (22CS10072)}
\date{}

\begin{document}

\maketitle

\section{Introduction}
This report details the cache hierarchy performance analysis of two MergeSort variants—Simple and Chunked—simulated on a RISC-V architecture using gem5. The primary objective is to evaluate how different cache configurations (L1/L2 sizes and associativities) influence execution time, cycles, and cache efficiency for memory-intensive sorting workloads.

\section{Algorithm Comparisons}

\subsection{Simple MergeSort}
The Simple MergeSort is a standard recursive implementation that operates on the entire 10MB dataset (2,621,440 integers). It exhibits high temporal locality during the recursion but suffers from poor spatial locality as it traverses large memory ranges, potentially leading to significant cache thrashing when the working set exceeds cache capacity.

\subsection{Chunked MergeSort}
The Chunked MergeSort is designed for better cache locality through a two-phase approach:
\begin{enumerate}
    \item \textbf{Phase 1 (Sorting):} The dataset is divided into 5 independent 2MB chunks. Each chunk is sorted in isolation, fitting more comfortably within typical L2 cache sizes.
    \item \textbf{Phase 2 (Merging):} An optimized $n$-way selection merge is performed across the sorted chunks. This phase is designed to provide linear streaming access patterns, which are highly efficient for modern hardware prefetchers and cache replacement policies.
\end{enumerate}

\section{Experimental Setup}
The simulations were conducted using the following parameters:
\begin{itemize}
    \item \textbf{CPU Model:} RiscvTimingSimpleCPU (1.0 GHz)
    \item \textbf{Memory System:} DDR3\_1600\_8x8 (512 MiB)
    \item \textbf{Cache Configuration:} Parameterized L1D Size (32-128kB), L2 Size (256-1024kB), and Associativity (4-16 way).
    \item \textbf{Data Generation:} In-memory random integer generation with fixed seed (42) to eliminate I/O overhead.
\end{itemize}

\section{Results and Analysis}

\subsection{Baseline Performance Comparison}
The table below compares the performance of both variants under the baseline configuration (L1D: 64kB, 8-way; L2: 512kB, 16-way).

\begin{table}[htbp]
\centering
\caption{Baseline Performance: Simple vs. Chunked MergeSort}
\label{tab:baseline}
\begin{tabular}{lSSSSS}
\toprule
\textbf{Variant} & \textbf{Time (s)} & \textbf{IPC} & \textbf{L1 Miss Rate} & \textbf{L2 Miss Rate} \\
\midrule
Chunked & 3.7195 & 0.3318 & 0.0134 & 0.5539 \\
Simple  & 4.2611 & 0.3168 & 0.0172 & 0.6891 \\
\bottomrule
\end{tabular}
\end{table}

\paragraph{Key Insight:} The Chunked variant is approximately \textbf{12.71\% faster} and achieves a \textbf{4.76\% higher IPC}. More importantly, it reduces the L2 miss rate significantly (from 68.91\% to 55.39\%), demonstrating much better utilization of the unified cache.

\subsection{Cache Scaling Impact}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.85\textwidth]{results/analysis_plots/plot_time_impact.png}
    \caption{Execution Time vs. L1 Size. The Chunked variant maintains a consistent performance lead across all sizes.}
    \label{fig:time_l1}
\end{figure}

As shown in Figure \ref{fig:time_l1}, execution time scales non-linearly with L1 size. For both algorithms, increasing L1 size provides diminishing returns once the hot set of the recursion fits within the cache.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.85\textwidth]{results/analysis_plots/plot_ipc_efficiency.png}
    \caption{CPU Efficiency (IPC) Comparison. The Chunked variant consistently achieves higher instructions per cycle.}
    \label{fig:ipc_comp}
\end{figure}

\subsection{Cache Sensitivity Analysis}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.85\textwidth]{results/analysis_plots/plot_simple_vs_chunked_comparison.png}
    \caption{Comprehensive Comparison Grid showing Time, Ticks, IPC, L1, and L2 miss rates for the baseline config.}
    \label{fig:comp_grid}
\end{figure}

The comprehensive analysis in Figure \ref{fig:comp_grid} confirms that the advantage of the Chunked MergeSort stems largely from its superior L2 cache behavior. By restricting sorting to smaller chunks, it prevents the displacement of useful data that occurs in the global recursion of the Simple variant.

\section{Top Configurations}
The best-performing cache configurations across our 162-run sweep were:

\begin{table}[htbp]
\centering
\caption{Top 3 Configurations by IPC}
\begin{tabular}{lccccr}
\toprule
\textbf{Variant} & \textbf{L1D Size} & \textbf{L2 Size} & \textbf{L1 Assoc} & \textbf{L2 Assoc} & \textbf{IPC} \\
\midrule
Chunked & 128kB & 1024kB & 4 & 4 & 0.3386 \\
Chunked & 128kB & 1024kB & 8 & 4 & 0.3385 \\
Chunked & 128kB & 1024kB & 16 & 4 & 0.3385 \\
\bottomrule
\end{tabular}
\end{table}

\section{Conclusion}
Our analysis demonstrates that software-level algorithmic changes (chunking and selection-merge) can be more effective than hardware-level cache expansions. The Chunked MergeSort outperforms the Simple variant in nearly every hardware configuration by optimizing for the "critical working set" size of the L2 cache. Specifically, it achieves 12.71\% faster execution and 4.76\% higher IPC at the baseline configuration, while reducing L2 cache misses from 68.91\% to 55.39\%. The optimal configuration found was L1D=128kB/4-way and L2=1024kB/4-way, achieving an IPC of 0.3386 for Chunked vs. 0.3241 for Simple. For a balanced system prioritizing performance-to-area ratio, a \textbf{L1D of 64kB/8-way and L2 of 512kB/16-way} offers excellent performance for these sorting tasks.

\end{document}