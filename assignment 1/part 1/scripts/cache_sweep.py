import subprocess
import re
import csv
import multiprocessing
import os

# --- PATH CONFIGURATION ---
SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
GEM5_ROOT = "/home/tishya/shivam/hpc/gem5"

GEM5_EXEC = os.path.join(GEM5_ROOT, "build/RISCV/gem5.opt")
CONFIG_SCRIPT = os.path.join(SCRIPT_DIR, "../configs/cache_config.py")
BINARY_PATH = os.path.join(SCRIPT_DIR, "../benchmarks/matrix_multiply")
OUTPUT_DIR = os.path.join(SCRIPT_DIR, "../results")
CSV_FILE = os.path.join(OUTPUT_DIR, "l1_sweep_results.csv")

# Parameter to sweep: L1 Data Cache Size
l1_sizes = ["16kB", "32kB", "64kB", "128kB", "256kB"]

def run_simulation(size):
    """Run a single simulation for a specific L1 size."""
    # Create a unique directory for this specific run
    run_dir = os.path.join(OUTPUT_DIR, f"l1_{size}")
    os.makedirs(run_dir, exist_ok=True)
    
    cmd = [
        GEM5_EXEC,
        "-d", run_dir,            # Output directory for stats.txt
        CONFIG_SCRIPT,
        f"--l1d_size={size}",     # The parameter we are sweeping
        f"--binary={BINARY_PATH}" # The binary to run
    ]
    
    print(f"-> Launching {size} simulation...")
    
    try:
        # Run gem5 (suppress massive terminal output)
        subprocess.run(cmd, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
        
        # Parse the stats.txt file generated by this run
        stats_path = os.path.join(run_dir, "stats.txt")
        
        if not os.path.exists(stats_path):
            return [size, "Error: No Stats", 0, 0]

        with open(stats_path, "r") as f:
            content = f.read()
            
            # Regex to find the specific metrics
            # 1. Execution Time (simSeconds)
            time_match = re.search(r"simSeconds\s+([0-9\.e\-]+)", content)
            sim_seconds = time_match.group(1) if time_match else "N/A"
            
            # 2. L1 Hits (system.cpu.dcache.overallHits::total)
            hits_match = re.search(r"system\.cpu\.dcache\.overallHits::total\s+(\d+)", content)
            hits = hits_match.group(1) if hits_match else "0"
            
            # 3. L1 Misses (system.cpu.dcache.overallMisses::total)
            miss_match = re.search(r"system\.cpu\.dcache\.overallMisses::total\s+(\d+)", content)
            misses = miss_match.group(1) if miss_match else "0"
            
            return [size, sim_seconds, hits, misses]

    except Exception as e:
        return [size, f"Error: {str(e)}", 0, 0]

if __name__ == "__main__":
    # Ensure results directory exists
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    
    # Detect CPU cores for parallelism
    num_workers = min(multiprocessing.cpu_count(), len(l1_sizes))
    print(f"Starting parallel sweep on {num_workers} cores...")
    
    # Run simulations in parallel
    with multiprocessing.Pool(num_workers) as pool:
        results = pool.map(run_simulation, l1_sizes)
    
    # Write results to CSV
    with open(CSV_FILE, "w", newline="") as f:
        writer = csv.writer(f)
        writer.writerow(["L1_Size", "Execution_Time", "Hits", "Misses"])
        writer.writerows(results)
        
    print(f"\nSweep Complete! Data saved to:\n{CSV_FILE}")